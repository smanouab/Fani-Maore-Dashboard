"""
Analyse des Caract√©ristiques Sismiques - 

Ce module fournit une analyse compl√®te des caract√©ristiques sismiques incluant :
- Distribution des magnitudes avec cat√©gorisation
- Distribution des profondeurs et impact sur les d√©g√¢ts
- Relations entre magnitude et profondeur
- Calcul et analyse du potentiel destructeur
- Analyse de l'√©nergie lib√©r√©e
- Tests statistiques avanc√©s

Converti depuis Jupyter notebook vers Streamlit.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from datetime import datetime
import warnings
import sys
import os

# Supprimer les avertissements
warnings.filterwarnings('ignore')

# Ajouter utils au chemin pour le chargement des donn√©es
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'utils'))

# Configuration matplotlib
plt.style.use('default')
sns.set_palette("husl")

def apply_custom_css():
    """Appliquer le CSS personnalis√© pour l'analyse des caract√©ristiques"""
    st.markdown("""
    <style>
    .characteristics-header {
        background: linear-gradient(135deg, #e74c3c 0%, #8e44ad 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 1.5rem;
        text-align: center;
    }
    
    .intro-section {
        background-color: #d4edda;
        padding: 20px;
        border-radius: 15px;
        margin: 15px 0;
        border-left: 4px solid #28a745;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    .intro-text {
        color: #155724;
        font-size: 16px;
        line-height: 1.6;
        margin: 0;
        text-align: center;
    }
    
    .analysis-section {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 4px solid #e74c3c;
    }
    
    .stats-container {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 4px solid #2ecc71;
        color: #155724;
        font-weight: 500;
    }
    
    .stats-container h4 {
        color: #155724;
        margin-bottom: 10px;
        font-weight: bold;
    }
    
    .stats-container p {
        color: #155724;
        margin: 5px 0;
        font-weight: 500;
    }
    
    .energy-metric {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 4px solid #ffc107;
        color: #856404;
        font-weight: 500;
    }
    
    .energy-metric h4 {
        color: #856404;
        margin-bottom: 10px;
        font-weight: bold;
    }
    
    .energy-metric p {
        color: #856404;
        margin: 5px 0;
        font-weight: 500;
    }
    
    .danger-alert {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 4px solid #dc3545;
        color: #721c24;
        font-weight: 500;
    }
    
    .danger-alert h4 {
        color: #721c24;
        margin-bottom: 10px;
        font-weight: bold;
    }
    
    .danger-alert p {
        color: #721c24;
        margin: 5px 0;
        font-weight: 500;
    }
    
    .metric-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

def clean_dataframe_for_display(df):
    """Nettoyer un DataFrame pour l'affichage Streamlit (√©viter les erreurs PyArrow)"""
    df_clean = df.copy()
    
    # CORRECTION DRASTIQUE : Identifier et corriger TOUTES les colonnes probl√©matiques
    problematic_columns = []
    
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            problematic_columns.append(col)
            
            # Strat√©gie en cascade pour nettoyer
            try:
                # 1. Essayer conversion num√©rique directe
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                
                # 2. Si trop de NaN, c'√©tait probablement du texte
                if df_clean[col].isna().sum() > len(df_clean) * 0.8:
                    # Revenir au texte original et forcer string
                    df_clean[col] = df[col].astype(str).replace({
                        'nan': 'N/A', 'None': 'N/A', '<NA>': 'N/A', 'NaT': 'N/A'
                    })
                    df_clean[col] = df_clean[col].astype('string')
                else:
                    # Garder comme num√©rique
                    df_clean[col] = df_clean[col].astype('float64')
                    
            except Exception as e:
                # En dernier recours : forcer string proprement
                df_clean[col] = df[col].astype(str).replace({
                    'nan': 'N/A', 'None': 'N/A', '<NA>': 'N/A', 'NaT': 'N/A'
                })
                df_clean[col] = df_clean[col].astype('string')
    
    # Diagnostic pour debug (optionnel, peut √™tre retir√©)
    if problematic_columns and len(problematic_columns) <= 3:
        st.info(f"üîß Colonnes nettoy√©es pour l'affichage: {', '.join(problematic_columns)}")
    
    return df_clean

def show_analyse_caracteristiques():
    """Fonction principale pour afficher l'analyse des caract√©ristiques"""
    
    # Appliquer le style personnalis√©
    apply_custom_css()
    
    # En-t√™te
    st.markdown("""
    <div class="characteristics-header">
        <h1>üî¨ Analyse des Caract√©ristiques Sismiques</h1>
        <p>Analyse approfondie des propri√©t√©s physiques des s√©ismes</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Obtenir les donn√©es filtr√©es depuis l'√©tat de session AVANT l'intro
    if 'filtered_df' not in st.session_state:
        st.error("‚ùå Donn√©es non disponibles. Veuillez retourner √† la page d'accueil.")
        return
    
    df = st.session_state.filtered_df
    
    if len(df) == 0:
        st.warning("‚ö†Ô∏è Aucune donn√©e ne correspond aux filtres s√©lectionn√©s.")
        return
    
    # Section d'introduction avec le bon nombre de s√©ismes
    st.markdown(f"""
    <div class="intro-section">
        <p style="text-align: center; font-weight: bold; line-height: 1.8; color: #155724; font-size: 16px; margin: 0;">
            ‚úÖ <strong>{len(df)} s√©ismes charg√©s et analys√©s</strong><br><br>
            Ce module permet d'analyser les <strong>caract√©ristiques physiques</strong> des s√©ismes. 
            Explorez la <strong>distribution des magnitudes</strong>, <strong>profondeurs</strong>, 
            le <strong>potentiel destructeur</strong> et l'<strong>√©nergie lib√©r√©e</strong>. 
            üìä S√©lectionnez un type d'analyse ci-dessous pour commencer votre exploration.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Pr√©parer les donn√©es avec les caract√©ristiques calcul√©es
    df = prepare_seismic_characteristics(df)
    
    # Section de s√©lection du type d'analyse
    st.subheader("üîç S√©lection du Type d'Analyse")
    
    analysis_type = st.selectbox(
        "Choisissez le type d'analyse des caract√©ristiques :",
        [
            "Distribution des magnitudes",
            "Distribution des profondeurs", 
            "Relation magnitude/profondeur",
            "Potentiel destructeur",
            "√ânergie lib√©r√©e"
        ],
        index=0,
        help="S√©lectionnez le type d'analyse physique √† effectuer"
    )
    
    # CORRECTION : R√©cup√©rer le DataFrame filtr√© depuis les filtres avanc√©s
    df_filtered = show_advanced_filters(df)
    
    # Afficher les m√©triques cl√©s avec les donn√©es filtr√©es
    show_key_metrics(df_filtered)
    
    # Ex√©cuter l'analyse s√©lectionn√©e avec les donn√©es filtr√©es
    if analysis_type == "Distribution des magnitudes":
        analyser_distribution_magnitudes(df_filtered)
    elif analysis_type == "Distribution des profondeurs":
        analyser_distribution_profondeurs(df_filtered)
    elif analysis_type == "Relation magnitude/profondeur":
        analyser_relation_magnitude_profondeur(df_filtered)
    elif analysis_type == "Potentiel destructeur":
        analyser_potentiel_destructeur(df_filtered)
    elif analysis_type == "√ânergie lib√©r√©e":
        analyser_energie(df_filtered)

def prepare_seismic_characteristics(df):
    """Pr√©parer les caract√©ristiques sismiques calcul√©es - VERSION CORRIG√âE"""
    
    df = df.copy()
    
    # CORRECTION : Nettoyer les types de donn√©es pour √©viter les erreurs PyArrow
    def clean_numeric_column(column):
        """Nettoyer une colonne num√©rique qui peut contenir des cha√Ænes"""
        if column.dtype == 'object':
            try:
                # Convertir en num√©rique, forcer les erreurs √† NaN
                return pd.to_numeric(column, errors='coerce')
            except:
                return column
        return column
    
    # Nettoyer les colonnes num√©riques principales
    numeric_columns = ['Magnitude', 'Profondeur', 'Latitude', 'Longitude']
    for col in numeric_columns:
        if col in df.columns:
            df[col] = clean_numeric_column(df[col])
    
    # DIAGNOSTIC : Afficher des informations sur les donn√©es avant traitement
    if 'Profondeur' in df.columns:
        profondeur_stats = df['Profondeur'].describe()
        st.info(f"üìä **Diagnostic des profondeurs** - Min: {profondeur_stats['min']:.3f} km, Max: {profondeur_stats['max']:.3f} km, Moyenne: {profondeur_stats['mean']:.3f} km")
        
        if profondeur_stats['mean'] < 2:  # Si la profondeur moyenne est < 2 km
            st.warning(f"‚ö†Ô∏è **Profondeurs suspectes d√©tect√©es !**")
            
            # Afficher un √©chantillon pour diagnostic
            sample_depths = df['Profondeur'].head(10).tolist()
            st.write(f"üîç √âchantillon des profondeurs: {sample_depths}")
            
            # Proposer une correction
            correction_factor = st.selectbox(
                "üîß Correction sugg√©r√©e :",
                [
                    "Aucune correction", 
                    "Multiplier par 100 (si en centaines de m√®tres)",
                    "Multiplier par 1000 (si en m√®tres)"
                ],
                help="Choisissez la correction appropri√©e selon vos unit√©s de donn√©es"
            )
            
            if correction_factor == "Multiplier par 100 (si en centaines de m√®tres)":
                df['Profondeur'] = df['Profondeur'] * 100
                st.success("‚úÖ Profondeurs corrig√©es : converties en kilom√®tres")
            elif correction_factor == "Multiplier par 1000 (si en m√®tres)":
                df['Profondeur'] = df['Profondeur'] / 1000
                st.success("‚úÖ Profondeurs corrig√©es : converties de m√®tres en kilom√®tres")
    
    # Nettoyer toutes les colonnes qui pourraient √™tre num√©riques
    for col in df.columns:
        if col not in ['Date', 'Localisation', 'Region'] and df[col].dtype == 'object':
            # Essayer de convertir en num√©rique si possible
            try:
                numeric_series = pd.to_numeric(df[col], errors='coerce')
                # Si plus de 50% des valeurs sont num√©riques, on garde la conversion
                if numeric_series.notna().sum() / len(df) > 0.5:
                    df[col] = numeric_series
            except:
                pass
    
    # Correction des profondeurs n√©gatives
    if (df['Profondeur'] < 0).any():
        st.warning(f"‚ö†Ô∏è {(df['Profondeur'] < 0).sum()} valeurs de profondeur n√©gatives d√©tect√©es. Application de la valeur absolue.")
        df['Profondeur'] = df['Profondeur'].abs()
    
    # CORRECTION : Traiter les profondeurs nulles ou tr√®s faibles
    # Remplacer les profondeurs nulles ou n√©gatives par 1 km (valeur minimale raisonnable)
    df['Profondeur'] = df['Profondeur'].replace(0, 1.0)  # Remplacer 0 par 1 km
    df['Profondeur'] = np.where(df['Profondeur'] < 0.1, 1.0, df['Profondeur'])  # Minimum 0.1 km
    
    # V√©rifier et corriger les valeurs NaN dans Magnitude et Profondeur
    if df['Magnitude'].isna().any():
        st.warning(f"‚ö†Ô∏è {df['Magnitude'].isna().sum()} valeurs de magnitude manquantes d√©tect√©es. Suppression des lignes.")
        df = df.dropna(subset=['Magnitude'])
    
    if df['Profondeur'].isna().any():
        st.warning(f"‚ö†Ô∏è {df['Profondeur'].isna().sum()} valeurs de profondeur manquantes d√©tect√©es. Suppression des lignes.")
        df = df.dropna(subset=['Profondeur'])
    
    # Cat√©gorisation des magnitudes
    def categorize_magnitude(mag):
        if pd.isna(mag):
            return 'Inconnu'
        if 0 <= mag < 2.5:
            return 'Micro'
        elif 2.5 <= mag < 4.0:
            return 'Faible'
        elif 4.0 <= mag < 5.0:
            return 'L√©ger'
        elif 5.0 <= mag < 6.0:
            return 'Mod√©r√©'
        elif 6.0 <= mag < 7.0:
            return 'Fort'
        elif 7.0 <= mag < 8.0:
            return 'Majeur'
        elif mag >= 8.0:
            return 'Grand'
        return 'Inconnu'
    
    df['Magnitude_Categorie'] = df['Magnitude'].apply(categorize_magnitude)
    
    # Cat√©gorisation des profondeurs
    def categorize_depth(depth):
        if pd.isna(depth):
            return 'Inconnu'
        if 0 <= depth < 70:
            return 'Peu profond'
        elif 70 <= depth < 300:
            return 'Interm√©diaire'
        elif depth >= 300:
            return 'Profond'
        return 'Inconnu'
    
    df['Profondeur_Categorie'] = df['Profondeur'].apply(categorize_depth)
    
    # Calcul de l'√©nergie lib√©r√©e (formule de Gutenberg-Richter : E = 10^(1.5*M+4.8))
    # ATTENTION : Ceci est une approximation bas√©e uniquement sur la magnitude
    df['Energie'] = np.where(
        df['Magnitude'].notna() & (df['Magnitude'] >= 0),
        10**(1.5 * df['Magnitude'] + 4.8),
        np.nan
    )
    
    # Ajouter un avertissement sur l'approximation
    if 'Energie' in df.columns and not hasattr(st.session_state, 'energy_warning_shown'):
        st.info("‚ÑπÔ∏è **Note sur l'√©nergie** : Calcul√©e avec la formule de Gutenberg-Richter (approximation bas√©e sur la magnitude). Incertitude typique : facteur 2-10.")
        st.session_state.energy_warning_shown = True
    
    # Calcul du potentiel destructeur - VERSION CORRIG√âE
    # Formule: Magnitude * (1 + 70/profondeur)
    # CORRECTION : S'assurer qu'il n'y a pas de division par z√©ro et limiter les valeurs extr√™mes
    df['Potentiel_Destructeur'] = np.where(
        (df['Magnitude'].notna()) & (df['Profondeur'].notna()) & (df['Profondeur'] > 0),
        df['Magnitude'] * (1 + np.minimum(70/df['Profondeur'], 1000)),  # Limiter √† 1000 max
        np.nan
    )
    
    # Supprimer les valeurs infinies ou NaN du potentiel destructeur
    if df['Potentiel_Destructeur'].isna().any():
        nb_nan = df['Potentiel_Destructeur'].isna().sum()
        st.warning(f"‚ö†Ô∏è {nb_nan} valeurs de potentiel destructeur invalides supprim√©es.")
        df = df.dropna(subset=['Potentiel_Destructeur'])
    
    # V√©rifier les valeurs infinies
    if np.isinf(df['Potentiel_Destructeur']).any():
        nb_inf = np.isinf(df['Potentiel_Destructeur']).sum()
        st.warning(f"‚ö†Ô∏è {nb_inf} valeurs infinies de potentiel destructeur d√©tect√©es et supprim√©es.")
        df = df[~np.isinf(df['Potentiel_Destructeur'])]
    
    # Cat√©gorisation du potentiel destructeur
    def categorize_potentiel(pot):
        if pd.isna(pot) or np.isinf(pot):
            return 'Inconnu'
        if 0 <= pot < 3:
            return 'Tr√®s faible'
        elif 3 <= pot < 6:
            return 'Faible'
        elif 6 <= pot < 10:
            return 'Mod√©r√©'
        elif 10 <= pot < 15:
            return '√âlev√©'
        elif pot >= 15:
            return 'Tr√®s √©lev√©'
        return 'Inconnu'
    
    df['Potentiel_Categorie'] = df['Potentiel_Destructeur'].apply(categorize_potentiel)
    
    # CORRECTION FINALE : S'assurer que toutes les colonnes num√©riques sont bien typ√©es
    numeric_cols_to_fix = ['Magnitude', 'Profondeur', 'Energie', 'Potentiel_Destructeur', 'Latitude', 'Longitude']
    for col in numeric_cols_to_fix:
        if col in df.columns:
            # Conversion agressive pour √©liminer les probl√®mes PyArrow
            df[col] = pd.to_numeric(df[col], errors='coerce').astype('float64')
    
    # Traiter sp√©cifiquement les colonnes cat√©gorielles
    categorical_cols = ['Magnitude_Categorie', 'Profondeur_Categorie', 'Potentiel_Categorie']
    for col in categorical_cols:
        if col in df.columns:
            df[col] = df[col].astype('string')
    
    # Traiter la colonne Date
    if 'Date' in df.columns:
        df['Date'] = df['Date'].astype('string')
    
    # SOLUTION DRASTIQUE : Nettoyer TOUTES les colonnes object probl√©matiques
    for col in df.columns:
        if df[col].dtype == 'object':
            # Essayer de convertir en num√©rique
            try:
                numeric_version = pd.to_numeric(df[col], errors='coerce')
                if numeric_version.notna().sum() > len(df) * 0.7:  # Si >70% sont num√©riques
                    df[col] = numeric_version.astype('float64')
                else:
                    # Forcer en string et nettoyer les valeurs probl√©matiques
                    df[col] = df[col].astype(str).replace({'nan': 'Inconnu', 'None': 'Inconnu'})
                    df[col] = df[col].astype('string')
            except:
                # En dernier recours, forcer en string
                df[col] = df[col].astype(str).replace({'nan': 'Inconnu', 'None': 'Inconnu'})
                df[col] = df[col].astype('string')
    
    # CORRECTION SP√âCIFIQUE : Forcer les types des colonnes critiques
    if 'Valeur' in df.columns:
        # Cette colonne cause l'erreur PyArrow
        df['Valeur'] = pd.to_numeric(df['Valeur'], errors='coerce').astype('float64')
        st.info("üîß Colonne 'Valeur' convertie en num√©rique pour √©viter les erreurs d'affichage.")
    
    return df

def show_advanced_filters(df):
    """Afficher les filtres avanc√©s pour l'analyse des caract√©ristiques"""
    
    with st.expander("üîß Filtres Avanc√©s par Cat√©gories", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Filtre par cat√©gorie de magnitude
            mag_categories = ['Micro', 'Faible', 'L√©ger', 'Mod√©r√©', 'Fort', 'Majeur', 'Grand']
            available_mag_cats = [cat for cat in mag_categories if cat in df['Magnitude_Categorie'].unique()]
            
            selected_mag_cats = st.multiselect(
                "Cat√©gories de magnitude",
                available_mag_cats,
                default=available_mag_cats,
                help="Filtrer par niveau de magnitude",
                key="filter_magnitude_cats"
            )
        
        with col2:
            # Filtre par cat√©gorie de profondeur
            depth_categories = ['Peu profond', 'Interm√©diaire', 'Profond']
            available_depth_cats = [cat for cat in depth_categories if cat in df['Profondeur_Categorie'].unique()]
            
            selected_depth_cats = st.multiselect(
                "Cat√©gories de profondeur",
                available_depth_cats,
                default=available_depth_cats,
                help="Filtrer par niveau de profondeur",
                key="filter_depth_cats"
            )
        
        with col3:
            # Filtre par potentiel destructeur
            pot_categories = ['Tr√®s faible', 'Faible', 'Mod√©r√©', '√âlev√©', 'Tr√®s √©lev√©']
            available_pot_cats = [cat for cat in pot_categories if cat in df['Potentiel_Categorie'].unique()]
            
            selected_pot_cats = st.multiselect(
                "Potentiel destructeur",
                available_pot_cats,
                default=available_pot_cats,
                help="Filtrer par potentiel de destruction",
                key="filter_potential_cats"
            )
        
        # CORRECTION : Retourner le DataFrame filtr√© au lieu de modifier session_state
        df_filtered = df.copy()
        
        # Appliquer les filtres avanc√©s
        if selected_mag_cats:
            df_filtered = df_filtered[df_filtered['Magnitude_Categorie'].isin(selected_mag_cats)]
        if selected_depth_cats:
            df_filtered = df_filtered[df_filtered['Profondeur_Categorie'].isin(selected_depth_cats)]
        if selected_pot_cats:
            df_filtered = df_filtered[df_filtered['Potentiel_Categorie'].isin(selected_pot_cats)]
        
        # Afficher le nombre de s√©ismes apr√®s filtrage
        if len(df_filtered) != len(df):
            st.info(f"üìä Filtres appliqu√©s : {len(df_filtered)} s√©ismes s√©lectionn√©s sur {len(df)} totaux")
        
        if len(df_filtered) == 0:
            st.warning("‚ö†Ô∏è Aucune donn√©e ne correspond aux filtres avanc√©s.")
        
        return df_filtered

def show_key_metrics(df):
    """Afficher les m√©triques cl√©s des caract√©ristiques sismiques"""
    
    st.subheader("üìä M√©triques Cl√©s")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("Magnitude moyenne", f"{df['Magnitude'].mean():.2f}")
        
    with col2:
        st.metric("Profondeur moyenne", f"{df['Profondeur'].mean():.1f} km")
        
    with col3:
        √©nergie_totale = df['Energie'].sum()
        st.metric("√ânergie totale", f"{√©nergie_totale:.2e} J")
        
    with col4:
        potentiel_max = df['Potentiel_Destructeur'].max()
        st.metric("Potentiel max", f"{potentiel_max:.1f}")
        
    with col5:
        s√©ismes_dangereux = len(df[df['Potentiel_Destructeur'] > 10])
        st.metric("S√©ismes √©lev√©s", s√©ismes_dangereux)

def analyser_distribution_magnitudes(df_filtered):
    """Analyser la distribution des magnitudes"""
    
    st.subheader("üìä Analyse des Magnitudes")
    
    if len(df_filtered) == 0:
        st.warning("Aucune donn√©e pour l'analyse des magnitudes.")
        return
    
    # 1. Distribution globale
    st.markdown("#### üìà Distribution globale des magnitudes")
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Histogramme avec courbe de densit√©
    ax1.hist(df_filtered['Magnitude'], bins=30, alpha=0.7, color='skyblue', edgecolor='black', density=True)
    
    # Ajouter une courbe de densit√©
    from scipy.stats import gaussian_kde
    kde = gaussian_kde(df_filtered['Magnitude'])
    x_range = np.linspace(df_filtered['Magnitude'].min(), df_filtered['Magnitude'].max(), 100)
    ax1.plot(x_range, kde(x_range), 'r-', linewidth=2, label='Densit√© estim√©e')
    
    ax1.axvline(df_filtered['Magnitude'].mean(), color='red', linestyle='--', 
               label=f'Moyenne: {df_filtered["Magnitude"].mean():.2f}')
    ax1.axvline(df_filtered['Magnitude'].median(), color='green', linestyle='--', 
               label=f'M√©diane: {df_filtered["Magnitude"].median():.2f}')
    
    ax1.set_title('Distribution des magnitudes')
    ax1.set_xlabel('Magnitude')
    ax1.set_ylabel('Densit√©')
    ax1.legend()
    ax1.grid(alpha=0.3)
    
    # Box plot
    ax2.boxplot(df_filtered['Magnitude'], vert=True, patch_artist=True,
                boxprops=dict(facecolor='lightblue', alpha=0.7))
    ax2.set_title('Box plot des magnitudes')
    ax2.set_ylabel('Magnitude')
    ax2.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 2. Distribution par cat√©gorie
    st.markdown("#### üè∑Ô∏è Distribution par cat√©gorie")
    
    order = ['Micro', 'Faible', 'L√©ger', 'Mod√©r√©', 'Fort', 'Majeur', 'Grand']
    order = [cat for cat in order if cat in df_filtered['Magnitude_Categorie'].unique()]
    
    mag_counts = df_filtered['Magnitude_Categorie'].value_counts().reindex(order)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    colors = plt.cm.YlOrRd(np.linspace(0.3, 0.9, len(order)))
    bars = ax.bar(order, mag_counts.values, color=colors, alpha=0.8, edgecolor='black')
    
    # Ajouter les valeurs et pourcentages
    total = len(df_filtered)
    for i, (bar, count) in enumerate(zip(bars, mag_counts.values)):
        percentage = count / total * 100
        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(mag_counts.values) * 0.01,
               f'{count}\n({percentage:.1f}%)', ha='center', va='bottom', fontweight='bold')
    
    ax.set_title('Nombre de s√©ismes par cat√©gorie de magnitude')
    ax.set_xlabel('Cat√©gorie de magnitude')
    ax.set_ylabel('Nombre de s√©ismes')
    ax.tick_params(axis='x', rotation=45)
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 3. Statistiques d√©taill√©es
    st.markdown("#### üìã Statistiques d√©taill√©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="stats-container">
            <h4>üìä Statistiques descriptives</h4>
        </div>
        """, unsafe_allow_html=True)
        
        stats_data = {
            "Statistique": ["Nombre total", "Minimum", "Maximum", "Moyenne", "M√©diane", "√âcart-type", "Skewness", "Kurtosis"],
            "Valeur": [
                len(df_filtered),
                f"{df_filtered['Magnitude'].min():.2f}",
                f"{df_filtered['Magnitude'].max():.2f}",
                f"{df_filtered['Magnitude'].mean():.2f}",
                f"{df_filtered['Magnitude'].median():.2f}",
                f"{df_filtered['Magnitude'].std():.2f}",
                f"{stats.skew(df_filtered['Magnitude']):.2f}",
                f"{stats.kurtosis(df_filtered['Magnitude']):.2f}"
            ]
        }
        st.dataframe(pd.DataFrame(stats_data), hide_index=True)
    
    with col2:
        st.markdown("""
        <div class="stats-container">
            <h4>üè∑Ô∏è R√©partition par cat√©gorie</h4>
        </div>
        """, unsafe_allow_html=True)
        
        category_data = []
        for category in order:
            count = mag_counts[category] if category in mag_counts.index else 0
            percentage = count / total * 100 if total > 0 else 0
            category_data.append({
                "Cat√©gorie": category,
                "Nombre": count,
                "Pourcentage": f"{percentage:.1f}%"
            })
        
        category_df = pd.DataFrame(category_data)
        category_df = clean_dataframe_for_display(category_df)
        st.dataframe(category_df, hide_index=True)

def analyser_distribution_profondeurs(df_filtered):
    """Analyser la distribution des profondeurs"""
    
    st.subheader("üï≥Ô∏è Analyse des Profondeurs")
    
    if len(df_filtered) == 0:
        st.warning("Aucune donn√©e pour l'analyse des profondeurs.")
        return
    
    # 1. Distribution globale
    st.markdown("#### üìà Distribution globale des profondeurs")
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Histogramme avec courbe de densit√©
    ax1.hist(df_filtered['Profondeur'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black', density=True)
    
    # Ajouter une courbe de densit√©
    from scipy.stats import gaussian_kde
    kde = gaussian_kde(df_filtered['Profondeur'])
    x_range = np.linspace(df_filtered['Profondeur'].min(), df_filtered['Profondeur'].max(), 100)
    ax1.plot(x_range, kde(x_range), 'darkred', linewidth=2, label='Densit√© estim√©e')
    
    ax1.axvline(df_filtered['Profondeur'].mean(), color='red', linestyle='--', 
               label=f'Moyenne: {df_filtered["Profondeur"].mean():.1f} km')
    ax1.axvline(df_filtered['Profondeur'].median(), color='green', linestyle='--', 
               label=f'M√©diane: {df_filtered["Profondeur"].median():.1f} km')
    
    ax1.set_title('Distribution des profondeurs')
    ax1.set_xlabel('Profondeur (km)')
    ax1.set_ylabel('Densit√©')
    ax1.legend()
    ax1.grid(alpha=0.3)
    
    # √âchelle logarithmique pour mieux voir la distribution
    ax2.hist(df_filtered['Profondeur'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')
    ax2.set_yscale('log')
    ax2.set_title('Distribution des profondeurs (√©chelle log)')
    ax2.set_xlabel('Profondeur (km)')
    ax2.set_ylabel('Nombre de s√©ismes (log)')
    ax2.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 2. Distribution par cat√©gorie
    st.markdown("#### üè∑Ô∏è Distribution par cat√©gorie de profondeur")
    
    order = ['Peu profond', 'Interm√©diaire', 'Profond']
    order = [cat for cat in order if cat in df_filtered['Profondeur_Categorie'].unique()]
    
    depth_counts = df_filtered['Profondeur_Categorie'].value_counts().reindex(order)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    colors = ['lightblue', 'steelblue', 'darkblue'][:len(order)]
    bars = ax.bar(order, depth_counts.values, color=colors, alpha=0.8, edgecolor='black')
    
    # Ajouter les valeurs et pourcentages
    total = len(df_filtered)
    for i, (bar, count) in enumerate(zip(bars, depth_counts.values)):
        percentage = count / total * 100
        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(depth_counts.values) * 0.01,
               f'{count}\n({percentage:.1f}%)', ha='center', va='bottom', fontweight='bold')
    
    ax.set_title('Nombre de s√©ismes par cat√©gorie de profondeur')
    ax.set_xlabel('Cat√©gorie de profondeur')
    ax.set_ylabel('Nombre de s√©ismes')
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 3. Impact de la profondeur sur les d√©g√¢ts potentiels
    st.markdown("#### ‚ö†Ô∏è Impact de la profondeur sur les d√©g√¢ts")
    
    st.markdown("""
    <div class="danger-alert">
        <h4>üö® Relation profondeur-d√©g√¢ts</h4>
        <p><strong>S√©ismes peu profonds (< 70 km) :</strong> Plus destructeurs en surface</p>
        <p><strong>S√©ismes interm√©diaires (70-300 km) :</strong> Impact mod√©r√©</p>
        <p><strong>S√©ismes profonds (> 300 km) :</strong> Moins ressentis en surface</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Analyse par cat√©gorie avec magnitude moyenne
    fig, ax = plt.subplots(figsize=(12, 6))
    
    avg_magnitude_by_depth = df_filtered.groupby('Profondeur_Categorie')['Magnitude'].mean().reindex(order)
    
    bars = ax.bar(order, avg_magnitude_by_depth.values, color=colors, alpha=0.8, edgecolor='black')
    
    for i, (bar, mag) in enumerate(zip(bars, avg_magnitude_by_depth.values)):
        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.05,
               f'{mag:.2f}', ha='center', va='bottom', fontweight='bold')
    
    ax.set_title('Magnitude moyenne par cat√©gorie de profondeur')
    ax.set_xlabel('Cat√©gorie de profondeur')
    ax.set_ylabel('Magnitude moyenne')
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

def analyser_relation_magnitude_profondeur(df_filtered):
    """Analyser la relation entre magnitude et profondeur"""
    
    st.subheader("üîó Relation Magnitude-Profondeur")
    
    if len(df_filtered) == 0:
        st.warning("Aucune donn√©e pour l'analyse des relations.")
        return
    
    # 1. Nuage de points avec potentiel destructeur
    st.markdown("#### üéØ Nuage de points avec potentiel destructeur")
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    scatter = ax.scatter(df_filtered['Profondeur'], df_filtered['Magnitude'], 
                        c=df_filtered['Potentiel_Destructeur'], cmap='YlOrRd', 
                        alpha=0.7, s=60, edgecolors='black', linewidth=0.5)
    
    plt.colorbar(scatter, label='Potentiel destructeur')
    
    # Ajouter une r√©gression lin√©aire
    if len(df_filtered) > 2:
        slope, intercept, r_value, p_value, std_err = stats.linregress(
            df_filtered['Profondeur'], df_filtered['Magnitude'])
        
        x_line = np.array([df_filtered['Profondeur'].min(), df_filtered['Profondeur'].max()])
        y_line = intercept + slope * x_line
        
        ax.plot(x_line, y_line, 'b--', linewidth=2,
               label=f'R√©gression: y={slope:.4f}x+{intercept:.2f} (r¬≤={r_value**2:.3f})')
        
        # Analyse statistique
        significance = "significative" if p_value < 0.05 else "non significative"
        direction = "positive" if slope > 0 else "n√©gative"
        
        # Gestion de l'affichage des p-values tr√®s petites
        if p_value < 1e-10:
            p_display = "< 1e-10 (extr√™mement significative)"
        elif p_value < 1e-6:
            p_display = f"{p_value:.2e} (tr√®s significative)"
        else:
            p_display = f"{p_value:.6f}"
        
        st.markdown(f"""
        <div class="stats-container">
            <h4>üìä Analyse de corr√©lation</h4>
            <p><strong>Coefficient de corr√©lation (r) :</strong> {r_value:.3f}</p>
            <p><strong>Coefficient de d√©termination (r¬≤) :</strong> {r_value**2:.3f}</p>
            <p><strong>p-value :</strong> {p_display}</p>
            <p><strong>Conclusion :</strong> Corr√©lation {direction} {significance}</p>
        </div>
        """, unsafe_allow_html=True)
    
    ax.set_title('Relation entre magnitude et profondeur\n(couleur = potentiel destructeur)')
    ax.set_xlabel('Profondeur (km)')
    ax.set_ylabel('Magnitude')
    ax.legend()
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

def analyser_potentiel_destructeur(df_filtered):
    """Analyser le potentiel destructeur - VERSION CORRIG√âE"""
    
    st.subheader("‚ö†Ô∏è Analyse du Potentiel Destructeur")
    
    # BO√éTE D'INFORMATION sur le potentiel destructeur
    with st.container():
        st.markdown("""
        <div style="background-color: #fff3cd; padding: 20px; border-radius: 15px; margin: 15px 0; border-left: 4px solid #ffc107; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
            <h4 style="color: #856404; margin-top: 0;">üßÆ √Ä propos du Potentiel Destructeur</h4>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("#### üìê Formule utilis√©e :")
        st.code("Potentiel = Magnitude √ó (1 + 70/Profondeur)", language="python")
        
        st.markdown("#### üéØ Principe :")
        st.markdown("""
        - **Plus la magnitude est √©lev√©e** ‚Üí Plus le potentiel destructeur augmente
        - **Plus le s√©isme est superficiel** ‚Üí Plus il est destructeur en surface  
        - **Coefficient 70** : Facteur d'amplification pour les s√©ismes peu profonds
        """)
        
        st.markdown("#### ‚ö†Ô∏è Limitations importantes :")
        st.markdown("""
        - üìä **Indicateur relatif** uniquement (pour comparer les s√©ismes entre eux)
        - üèóÔ∏è **Ne remplace pas** les √©tudes d'ing√©nierie sismique professionnelles
        - üåç **N'inclut pas** : g√©ologie locale, type de sol, distance √©picentrale
        - üèòÔ∏è **N'√©value pas** l'impact r√©el sur les infrastructures
        """)
        
        st.markdown("#### üîç Fonctionnalit√© de cette analyse :")
        st.markdown("""
        - üìà **Distribution** : Voir la r√©partition des niveaux de dangerosit√©
        - üèÜ **Classement** : Identifier les s√©ismes les plus pr√©occupants
        - üìä **Statistiques** : Comprendre les tendances de votre dataset
        - üéØ **Cat√©gorisation** : Regroupement en niveaux (Tr√®s faible ‚Üí Tr√®s √©lev√©)
        """)
    
    if len(df_filtered) == 0:
        st.warning("Aucune donn√©e pour l'analyse du potentiel destructeur.")
        return
    
    # CORRECTION : V√©rifications suppl√©mentaires avant l'analyse
    if 'Potentiel_Destructeur' not in df_filtered.columns:
        st.error("‚ùå Colonne 'Potentiel_Destructeur' manquante.")
        return
    
    # Nettoyer les donn√©es avant l'analyse
    df_clean = df_filtered.copy()
    
    # Supprimer les valeurs NaN ou infinies
    initial_count = len(df_clean)
    df_clean = df_clean[df_clean['Potentiel_Destructeur'].notna()]
    df_clean = df_clean[~np.isinf(df_clean['Potentiel_Destructeur'])]
    df_clean = df_clean[df_clean['Potentiel_Destructeur'] >= 0]  # Valeurs positives seulement
    
    cleaned_count = len(df_clean)
    if cleaned_count < initial_count:
        st.info(f"‚ÑπÔ∏è {initial_count - cleaned_count} valeurs invalides supprim√©es de l'analyse.")
    
    if len(df_clean) == 0:
        st.error("‚ùå Aucune donn√©e valide pour l'analyse du potentiel destructeur.")
        return
    
    # 1. Distribution du potentiel destructeur
    st.markdown("#### üìä Distribution du potentiel destructeur")
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Histogramme - avec v√©rification des donn√©es
    try:
        potentiel_data = df_clean['Potentiel_Destructeur'].values
        
        # V√©rifier qu'il y a des donn√©es et qu'elles sont valides
        if len(potentiel_data) > 0 and not np.all(np.isnan(potentiel_data)):
            ax1.hist(potentiel_data, bins=min(30, len(potentiel_data)//2), alpha=0.7, 
                     color='orange', edgecolor='black', density=True)
            
            mean_val = np.nanmean(potentiel_data)
            median_val = np.nanmedian(potentiel_data)
            
            ax1.axvline(mean_val, color='red', linestyle='--', 
                       label=f'Moyenne: {mean_val:.2f}')
            ax1.axvline(median_val, color='green', linestyle='--', 
                       label=f'M√©diane: {median_val:.2f}')
            
            ax1.set_title('Distribution du potentiel destructeur')
            ax1.set_xlabel('Potentiel destructeur')
            ax1.set_ylabel('Densit√©')
            ax1.legend()
            ax1.grid(alpha=0.3)
        else:
            ax1.text(0.5, 0.5, 'Donn√©es insuffisantes', transform=ax1.transAxes, 
                    ha='center', va='center', fontsize=14)
            ax1.set_title('Distribution du potentiel destructeur - Donn√©es insuffisantes')
    
    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation de l'histogramme: {str(e)}")
        ax1.text(0.5, 0.5, 'Erreur de visualisation', transform=ax1.transAxes, 
                ha='center', va='center', fontsize=14)
    
    # Distribution par cat√©gorie
    try:
        order = ['Tr√®s faible', 'Faible', 'Mod√©r√©', '√âlev√©', 'Tr√®s √©lev√©']
        order = [cat for cat in order if cat in df_clean['Potentiel_Categorie'].unique()]
        
        if len(order) > 0:
            potentiel_counts = df_clean['Potentiel_Categorie'].value_counts().reindex(order)
            colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(order)))
            
            bars = ax2.bar(order, potentiel_counts.values, color=colors, alpha=0.8, edgecolor='black')
            
            total = len(df_clean)
            for i, (bar, count) in enumerate(zip(bars, potentiel_counts.values)):
                if not pd.isna(count) and count > 0:
                    percentage = count / total * 100
                    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height(),
                           f'{int(count)}\n({percentage:.1f}%)', ha='center', va='bottom', fontweight='bold')
            
            ax2.set_title('Nombre de s√©ismes par cat√©gorie de potentiel')
            ax2.set_xlabel('Cat√©gorie de potentiel destructeur')
            ax2.set_ylabel('Nombre de s√©ismes')
            ax2.tick_params(axis='x', rotation=45)
            ax2.grid(alpha=0.3)
        else:
            ax2.text(0.5, 0.5, 'Aucune cat√©gorie disponible', transform=ax2.transAxes, 
                    ha='center', va='center', fontsize=14)
    
    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation du graphique par cat√©gorie: {str(e)}")
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 2. Analyse des s√©ismes les plus dangereux
    st.markdown("#### üö® S√©ismes √† fort potentiel destructeur")
    
    try:
        # Identifier les s√©ismes les plus dangereux (top 10%)
        if len(df_clean) > 10:  # S'assurer qu'il y a assez de donn√©es
            seuil_danger = df_clean['Potentiel_Destructeur'].quantile(0.9)
            seismes_dangereux = df_clean[df_clean['Potentiel_Destructeur'] >= seuil_danger]
            
            if len(seismes_dangereux) > 0:
                pourcentage_dangereux = len(seismes_dangereux)/len(df_clean)*100
                
                # Utiliser les composants Streamlit natifs au lieu du HTML
                st.warning("‚ö†Ô∏è **S√©ismes √† surveiller**")
                st.write(f"**{len(seismes_dangereux)} s√©ismes** ont un potentiel destructeur √©lev√© (‚â• {seuil_danger:.1f})")
                st.write(f"Ces s√©ismes repr√©sentent **{pourcentage_dangereux:.1f}%** des **{len(df_clean)}** s√©ismes analys√©s")
                st.info("*Note: Ce sont les 10% les plus dangereux par d√©finition (quantile 90%)*")
                
                # Afficher des statistiques sur les s√©ismes dangereux sans le tableau d√©taill√©
                col1, col2, col3 = st.columns(3)
                with col1:
                    magnitude_max = seismes_dangereux['Magnitude'].max()
                    st.metric("üî• Magnitude maximale", f"{magnitude_max:.2f}")
                
                with col2:
                    potentiel_max = seismes_dangereux['Potentiel_Destructeur'].max()
                    st.metric("‚ö° Potentiel max", f"{potentiel_max:.1f}")
                
                with col3:
                    profondeur_min = seismes_dangereux['Profondeur'].min()
                    st.metric("üìè Prof. minimale", f"{profondeur_min:.1f} km")
            else:
                st.info("‚ÑπÔ∏è Aucun s√©isme avec un potentiel destructeur particuli√®rement √©lev√© d√©tect√©.")
        else:
            st.info("‚ÑπÔ∏è Donn√©es insuffisantes pour l'analyse des s√©ismes dangereux.")
    
    except Exception as e:
        st.error(f"Erreur lors de l'analyse des s√©ismes dangereux: {str(e)}")
        
    # 3. Statistiques du potentiel destructeur
    st.markdown("#### üìä Statistiques du potentiel destructeur")
    
    try:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="stats-container">
                <h4>üìä Statistiques descriptives</h4>
            </div>
            """, unsafe_allow_html=True)
            
            stats_data = {
                "Statistique": ["Nombre total", "Minimum", "Maximum", "Moyenne", "M√©diane", "√âcart-type"],
                "Valeur": [
                    str(len(df_clean)),
                    f"{float(df_clean['Potentiel_Destructeur'].min()):.2f}",
                    f"{float(df_clean['Potentiel_Destructeur'].max()):.2f}",
                    f"{float(df_clean['Potentiel_Destructeur'].mean()):.2f}",
                    f"{float(df_clean['Potentiel_Destructeur'].median()):.2f}",
                    f"{float(df_clean['Potentiel_Destructeur'].std()):.2f}"
                ]
            }
            # Forcer les types pour √©viter les erreurs PyArrow
            stats_df = pd.DataFrame(stats_data)
            stats_df = stats_df.astype({'Statistique': 'string', 'Valeur': 'string'})
            st.dataframe(stats_df, hide_index=True)
        
        with col2:
            if len(order) > 0:
                st.markdown("""
                <div class="stats-container">
                    <h4>üè∑Ô∏è R√©partition par cat√©gorie</h4>
                </div>
                """, unsafe_allow_html=True)
                
                category_data = []
                for category in order:
                    count = potentiel_counts[category] if category in potentiel_counts.index else 0
                    percentage = count / len(df_clean) * 100 if len(df_clean) > 0 else 0
                    category_data.append({
                        "Cat√©gorie": str(category),
                        "Nombre": str(int(count) if not pd.isna(count) else 0),
                        "Pourcentage": f"{float(percentage):.1f}%"
                    })
                
                # Forcer les types pour √©viter les erreurs PyArrow
                category_df = pd.DataFrame(category_data)
                category_df = clean_dataframe_for_display(category_df)
                st.dataframe(category_df, hide_index=True)
    
    except Exception as e:
        st.error(f"Erreur lors du calcul des statistiques: {str(e)}")

def analyser_energie(df_filtered):
    """Analyser l'√©nergie lib√©r√©e par les s√©ismes"""
    
    st.subheader("‚ö° Analyse de l'√ânergie Lib√©r√©e")
    
    # BO√éTE D'INFORMATION sur l'√©nergie lib√©r√©e
    with st.container():
        st.markdown("""
        <div style="background-color: #d1ecf1; padding: 20px; border-radius: 15px; margin: 15px 0; border-left: 4px solid #bee5eb; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
            <h4 style="color: #0c5460; margin-top: 0;">‚ö° √Ä propos de l'√ânergie Sismique</h4>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("#### üìê Formule de Gutenberg-Richter :")
        st.code("E = 10^(1.5 √ó Magnitude + 4.8)   # Joules", language="python")
        
        st.markdown("#### üéØ Principe physique :")
        st.markdown("""
        - **√ânergie totale** lib√©r√©e lors de la rupture de la faille
        - **√âchelle logarithmique** : +1 magnitude = √ó32 en √©nergie
        - **Formule universelle** utilis√©e en sismologie mondiale
        """)
        
        st.markdown("#### ‚ö†Ô∏è Pr√©cision et limitations :")
        st.markdown("""
        - ‚úÖ **Approximation scientifique standard** (bas√©e sur la magnitude uniquement)
        - ‚ö° **Incertitude typique** : facteur 2 √† 10 (selon m√©canisme de rupture)
        - üéØ **Plus pr√©cise pour** magnitudes > 4.0
        - üö´ **N'inclut pas** : m√©canisme focal, g√©ologie, dur√©e de rupture
        """)
        
        st.markdown("#### üî¨ Fonctionnalit√© de cette analyse :")
        st.markdown("""
        - üìä **Distribution √©nerg√©tique** : Visualiser la r√©partition des √©nergies
        - üìà **√âvolution temporelle** : Suivre l'accumulation d'√©nergie dans le temps
        - üè∑Ô∏è **Contribution par magnitude** : Voir quelles cat√©gories lib√®rent le plus d'√©nergie
        - üìè **Relation th√©orique** : V√©rifier la conformit√© √† la loi de Gutenberg-Richter
        - üî¢ **Ordres de grandeur** : Comprendre la puissance relative des s√©ismes
        """)
        
        st.markdown("#### üí° Interpr√©tation :")
        st.info("""
        Cette analyse vous permet de **comparer quantitativement** la puissance des s√©ismes 
        et d'identifier les **√©v√©nements les plus √©nerg√©tiques** de votre dataset.
        """)
    
    if len(df_filtered) == 0:
        st.warning("Aucune donn√©e pour l'analyse de l'√©nergie.")
        return
    
    # 1. Distribution de l'√©nergie
    st.markdown("#### üìä Distribution de l'√©nergie lib√©r√©e")
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Distribution normale
    ax1.hist(df_filtered['Energie'], bins=30, alpha=0.7, color='gold', edgecolor='black')
    ax1.set_title('Distribution de l\'√©nergie')
    ax1.set_xlabel('√ânergie (Joules)')
    ax1.set_ylabel('Nombre de s√©ismes')
    ax1.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))
    ax1.grid(alpha=0.3)
    
    # Distribution logarithmique
    log_energie = np.log10(df_filtered['Energie'])
    ax2.hist(log_energie, bins=30, alpha=0.7, color='orange', edgecolor='black')
    ax2.set_title('Distribution de l\'√©nergie (√©chelle log)')
    ax2.set_xlabel('√ânergie (log‚ÇÅ‚ÇÄ Joules)')
    ax2.set_ylabel('Nombre de s√©ismes')
    ax2.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 2. √ânergie cumul√©e dans le temps
    st.markdown("#### üìà √âvolution de l'√©nergie cumul√©e")
    
    if 'Date' in df_filtered.columns:
        try:
            # Conversion s√©curis√©e des dates
            df_sorted = df_filtered.copy()
            
            # Essayer diff√©rents formats de date
            try:
                df_sorted['Date_converted'] = pd.to_datetime(df_sorted['Date'], format='%d/%m/%y %H:%M', errors='coerce')
            except:
                try:
                    df_sorted['Date_converted'] = pd.to_datetime(df_sorted['Date'], format='%d/%m/%Y %H:%M', errors='coerce')
                except:
                    df_sorted['Date_converted'] = pd.to_datetime(df_sorted['Date'], errors='coerce')
            
            # V√©rifier si la conversion a r√©ussi
            if df_sorted['Date_converted'].notna().any():
                df_sorted = df_sorted[df_sorted['Date_converted'].notna()].sort_values('Date_converted')
                energie_cumulee = df_sorted['Energie'].cumsum()
                
                fig, ax = plt.subplots(figsize=(14, 6))
                ax.plot(df_sorted['Date_converted'], energie_cumulee, linewidth=2, color='red')
                ax.set_title('√ânergie sismique cumul√©e au fil du temps')
                ax.set_xlabel('Date')
                ax.set_ylabel('√ânergie cumul√©e (Joules)')
                ax.set_yscale('log')
                ax.grid(alpha=0.3)
                
                # Ajouter des informations sur les pics d'√©nergie
                try:
                    max_daily_energy = df_sorted.groupby(df_sorted['Date_converted'].dt.date)['Energie'].sum()
                    if len(max_daily_energy) > 0:
                        top_energy_day = max_daily_energy.idxmax()
                        max_energy_value = max_daily_energy.max()
                        
                        st.markdown(f"""
                        <div class="energy-metric">
                            <h4>‚ö° Pic d'√©nergie</h4>
                            <p><strong>Jour le plus √©nerg√©tique :</strong> {top_energy_day}</p>
                            <p><strong>√ânergie lib√©r√©e :</strong> {max_energy_value:.2e} Joules</p>
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    st.info(f"‚ÑπÔ∏è Impossible de calculer les pics d'√©nergie: {str(e)}")
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
            else:
                st.warning("‚ö†Ô∏è Impossible de convertir les dates pour l'analyse temporelle.")
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erreur lors de l'analyse temporelle: {str(e)}")
            st.info("‚ÑπÔ∏è L'analyse temporelle a √©t√© ignor√©e en raison du format des dates.")
    
    # 3. R√©partition de l'√©nergie par cat√©gorie de magnitude
    st.markdown("#### üè∑Ô∏è R√©partition de l'√©nergie par cat√©gorie")
    
    order = ['Micro', 'Faible', 'L√©ger', 'Mod√©r√©', 'Fort', 'Majeur', 'Grand']
    order = [cat for cat in order if cat in df_filtered['Magnitude_Categorie'].unique()]
    
    # Calculer l'√©nergie totale par cat√©gorie
    energie_par_categorie = df_filtered.groupby('Magnitude_Categorie')['Energie'].sum().reindex(order)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    colors = plt.cm.YlOrRd(np.linspace(0.3, 0.9, len(order)))
    bars = ax.bar(order, energie_par_categorie.values, color=colors, alpha=0.8, edgecolor='black')
    
    ax.set_title('√ânergie totale lib√©r√©e par cat√©gorie de magnitude')
    ax.set_xlabel('Cat√©gorie de magnitude')
    ax.set_ylabel('√ânergie totale (Joules)')
    ax.set_yscale('log')
    ax.tick_params(axis='x', rotation=45)
    ax.grid(alpha=0.3)
    
    # Ajouter les pourcentages
    total_energy = energie_par_categorie.sum()
    for i, (bar, energy) in enumerate(zip(bars, energie_par_categorie.values)):
        percentage = energy / total_energy * 100
        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.1,
               f'{percentage:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 4. Relation √©nergie-magnitude (loi de Gutenberg-Richter)
    st.markdown("#### üìè Relation √©nergie-magnitude")
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    scatter = ax.scatter(df_filtered['Magnitude'], np.log10(df_filtered['Energie']), 
                        alpha=0.6, c=df_filtered['Profondeur'], cmap='viridis', s=50)
    
    plt.colorbar(scatter, label='Profondeur (km)')
    
    # Ajouter la relation th√©orique E = 10^(1.5*M+4.8)
    mag_theory = np.linspace(df_filtered['Magnitude'].min(), df_filtered['Magnitude'].max(), 100)
    log_energy_theory = 1.5 * mag_theory + 4.8
    
    ax.plot(mag_theory, log_energy_theory, 'r--', linewidth=2, 
           label='Relation th√©orique: log‚ÇÅ‚ÇÄ(E) = 1.5M + 4.8')
    
    ax.set_title('Relation entre magnitude et √©nergie lib√©r√©e')
    ax.set_xlabel('Magnitude')
    ax.set_ylabel('√ânergie (log‚ÇÅ‚ÇÄ Joules)')
    ax.legend()
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    # 5. Statistiques √©nerg√©tiques
    st.markdown("#### üìä Statistiques √©nerg√©tiques")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div class="energy-metric">
            <h4>‚ö° M√©triques globales</h4>
        </div>
        """, unsafe_allow_html=True)
        
        total_energie = df_filtered['Energie'].sum()
        moyenne_energie = df_filtered['Energie'].mean()
        max_energie = df_filtered['Energie'].max()
        
        energy_stats = {
            "M√©trique": ["√ânergie totale", "√ânergie moyenne", "√ânergie maximale", "√ânergie m√©diane"],
            "Valeur": [
                f"{total_energie:.2e} J",
                f"{moyenne_energie:.2e} J",
                f"{max_energie:.2e} J",
                f"{df_filtered['Energie'].median():.2e} J"
            ]
        }
        energy_stats_df = pd.DataFrame(energy_stats)
        energy_stats_df = clean_dataframe_for_display(energy_stats_df)
        st.dataframe(energy_stats_df, hide_index=True)
    
    with col2:
        st.markdown("""
        <div class="energy-metric">
            <h4>üè∑Ô∏è Contribution par cat√©gorie</h4>
        </div>
        """, unsafe_allow_html=True)
        
        energy_contribution = []
        for category in order:
            if category in df_filtered['Magnitude_Categorie'].unique():
                cat_energy = df_filtered[df_filtered['Magnitude_Categorie'] == category]['Energie'].sum()
                percentage = cat_energy / total_energie * 100
                count = len(df_filtered[df_filtered['Magnitude_Categorie'] == category])
                
                energy_contribution.append({
                    "Cat√©gorie": category,
                    "√ânergie": f"{cat_energy:.2e} J",
                    "Contribution": f"{percentage:.1f}%",
                    "Nombre": count
                })
        
        if energy_contribution:
            energy_df = pd.DataFrame(energy_contribution)
            energy_df = clean_dataframe_for_display(energy_df)
            st.dataframe(energy_df, hide_index=True)

# Fonction principale qui peut √™tre appel√©e depuis app.py
def main():
    """Fonction principale √† appeler depuis l'application principale"""
    show_analyse_caracteristiques()

if __name__ == "__main__":
    main()
